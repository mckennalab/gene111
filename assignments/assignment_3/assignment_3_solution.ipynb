{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment three -- more flexible matches\n",
    "\n",
    "In this assignment we're going to try out some approaches to find inexact or fuzzy sequence matches. \n",
    "We'll use the built-in regular expression library to find some restriction enzyme sites in various \n",
    "DNA fragments. \n",
    "\n",
    "Regular expressions are complex! We'll just use a small fraction of their power, but the Python documentation\n",
    "goes into a great deal more depth on the various features they support:\n",
    "\n",
    "- [Python regex (re) docs](https://docs.python.org/3/library/re.html)\n",
    "\n",
    "One word of caution, regular expressions have very complicated implementations, with a bunch of performance 'gotchas'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the regular expression (re) library\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic example of finding a match\n",
    "\n",
    "There are many ways to use regular expressions. Python allows you to 'compile' regular expressions before you use them. Making the regular expression state machine is expensive, so this saves time later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found TTTTA\n"
     ]
    }
   ],
   "source": [
    "nucleotides = 'ACGTTTTAAGACAGATTA'\n",
    "pattern = re.compile(\"TTTTA\")\n",
    "match = pattern.search(nucleotides)\n",
    "\n",
    "if match:\n",
    "  print('found', match.group())\n",
    "else:\n",
    "  print('did not find')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degenerate bases\n",
    "\n",
    "Now lets start allowing sets of characters, in this case any DNA base, in our regular expression. Lets look for the same pattern except with two Ns at the end:\n",
    "\n",
    "TTTTANN\n",
    "\n",
    "Which we convert into the regular expression pattern:\n",
    "\n",
    "TTTTA[ACGT][ACGT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found TTTTAAG\n"
     ]
    }
   ],
   "source": [
    "nucleotides = 'ACGTTTTAAGACAGATTA'\n",
    "pattern = re.compile(\"TTTTA[ACGT][ACGT]\")\n",
    "match = pattern.search(nucleotides)\n",
    "\n",
    "if match:\n",
    "  print('found', match.group())\n",
    "else:\n",
    "  print('did not find')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matches and positions\n",
    "\n",
    "Often we want to find all the matches and their positions in a target sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 CG\n",
      "4 CG\n",
      "11 CG\n",
      "13 CG\n"
     ]
    }
   ],
   "source": [
    "pattern_CG = re.compile(\"CG\")\n",
    "nucleotides = 'ACGTCGTAAGACGCGATTA'\n",
    "\n",
    "for match in pattern_CG.finditer(nucleotides):\n",
    "    print(match.start(), match.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repetition qualifiers\n",
    "\n",
    "Regex also supports a number of repetition qualifiers, ways to repeate a pattern for either as many times as \n",
    "possible (the * operator), called greedy matching, non-greedy (? operator), or a set number or range of times (curly brackets {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 CCCCCG\n",
      "8 CG\n",
      "13 G\n",
      "15 CG\n",
      "17 CG\n"
     ]
    }
   ],
   "source": [
    "pattern_CG = re.compile(\"C*G\") # we match on as many Cs as possible, followed by a G\n",
    "nucleotides = 'ACCCCCGTCGTAAGACGCGATTA'\n",
    "\n",
    "for match in pattern_CG.finditer(nucleotides):\n",
    "    print(match.start(), match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 CCCG\n"
     ]
    }
   ],
   "source": [
    "pattern_CG = re.compile(\"C{3}G\") # three Cs followed by a G\n",
    "nucleotides = 'ACCCCCGTCGTAAGACGCGATTA'\n",
    "\n",
    "for match in pattern_CG.finditer(nucleotides):\n",
    "    print(match.start(), match.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in a list of restriction sites\n",
    "\n",
    "There are many, many restriction enzymes out there (see the list starting with 'A' [here](https://en.wikipedia.org/wiki/List_of_restriction_enzyme_cutting_sites:_A)). I pulled a shorter\n",
    "list from [Promega](https://www.promega.com/resources/guides/nucleic-acid-analysis/restriction-enzyme-resource/restriction-enzyme-resource-tables/), \n",
    "which has a relatively small collection. Here we can read in each restriction enzyme with its recognition sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AatII with sequence GACGTC\n",
      "AccB7I with sequence CCANNNNNTGG\n",
      "AccIII with sequence TCCGGA\n",
      "Acc65I with sequence GGTACC\n",
      "ApaI with sequence GGGCCC\n",
      "AvaI with sequence CYCGRG\n",
      "AvaII with sequence GGWCC\n",
      "Bal I with sequence TGGCCA\n",
      "BamHI with sequence GGATCC\n",
      "BanII with sequence GRGCYC\n",
      "BbuI with sequence GCATGC\n",
      "Bcl I with sequence TGATCA\n",
      "BglI with sequence GCCNNNNNGGC\n",
      "BssHII with sequence GCGCGC\n",
      "BglII with sequence AGATCT\n",
      "BsaOI with sequence CGRYCG\n",
      "Bsp1286 I with sequence GDGCHC\n",
      "BsrBRI with sequence GATNN\n",
      "BstEII with sequence GGTNACC\n",
      "BstOI with sequence CCWGG\n",
      "BstXI with sequence CCANNNNNNTGG\n",
      "BstZI with sequence CGGCCG\n",
      "CfoI with sequence GCGC\n",
      "ClaI with sequence ATCGAT\n",
      "CspI with sequence CGGWCCG\n",
      "Csp45I with sequence TTCGAA\n",
      "DdeI with sequence CTNAG\n",
      "Eco47III with sequence AGCGCT\n",
      "Eco52I with sequence CGGCCG\n",
      "EcoRI with sequence GAATTC\n",
      "FokI with sequence GGATG\n",
      "HaeIII with sequence GGCC\n",
      "HhaI with sequence GCGC\n",
      "HincII with sequence GTYRAC\n",
      "HindIII with sequence AAGCTT\n",
      "HpaII with sequence CCGG\n",
      "KpnI with sequence GGTACC\n",
      "MboI with sequence GATC\n",
      "MboII with sequence GAAGA\n",
      "MluI with sequence ACGCGT\n",
      "MspI with sequence CCGG\n",
      "NaeI with sequence GCCGGC\n",
      "NarI with sequence GGCGCC\n",
      "NdeII with sequence GATC\n",
      "NgoMIV with sequence GCCGGC\n",
      "NheI with sequence GCTAGC\n",
      "NotI with sequence GCGGCCGC\n",
      "NruI with sequence TCGCGA\n",
      "PstI with sequence CTGCAG\n",
      "PvuI with sequence CGATCG\n",
      "PvuII with sequence CAGCTG\n",
      "SacI with sequence GAGCTC\n",
      "SacII with sequence CCGCGG\n",
      "Sal I with sequence GTCGAC\n",
      "Sau3AI with sequence GATC\n",
      "Sau96I with sequence GGNCC\n",
      "ScaI with sequence AGTACT\n",
      "SfiI with sequence GGCCNNNNNGGCC\n",
      "Sfga1 with sequence GCGATCGC\n",
      "SinI with sequence GGWCC\n",
      "SmaI with sequence CCCGGG\n",
      "SnaBI with sequence TACGTA\n",
      "SphI with sequence GCATGC\n",
      "StuI with sequence AGGCCT\n",
      "TaqI with sequence TCGA\n",
      "Tth111 with sequence GACNNNGTC\n",
      "XbaI with sequence TCTAGA\n",
      "XhoI with sequence CTCGAG\n",
      "XhoII with sequence RGATCY\n",
      "XmaI with sequence CCCGGG\n",
      "XmnI with sequence GAANNNNTTC\n"
     ]
    }
   ],
   "source": [
    "with open(\"restriction_enzymes_promega.txt\") as promega_file:\n",
    "    header = promega_file.readline()\n",
    "    for restriction_line in promega_file:\n",
    "        line_split_into_tokens = restriction_line.strip().split(\"\\t\")\n",
    "        print(line_split_into_tokens[0] + \" with sequence \" + line_split_into_tokens[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework time (6 points)\n",
    "\n",
    "The assignment is just one function, but it's a bit more complex than functions we've designed before. You saw above that we can compile regular expressions \n",
    "into a variable. We can then use that variable to perform subsequent matches. Here we're going to create a function that given a name and degenerate pattern \n",
    "creates a regex that matches all possible sequences with that pattern. For instance:\n",
    "    \n",
    "XmnI recognizes the pattern GAANNNNTTC. The returned compiled regex should match GAA __TTAA__ TTC or GAA __GGGA__ TTC.\n",
    "\n",
    "You should support all of the standard FASTA codes that apply to DNA (A,C,G,T,R,Y,K,M,S,W,B,D,H,V,N) from the [wikipedia page](https://en.wikipedia.org/wiki/FASTA_format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completing this function is your homework\n",
    "def restriction_regex_generator(sequence_pattern):\n",
    "    \n",
    "    compiled_regex_string = \"\"\n",
    "    \n",
    "    for base in sequence_pattern.upper():\n",
    "        if base == 'A' or base == 'T' or base == 'C' or base == 'G':\n",
    "            compiled_regex_string += base\n",
    "        elif base == 'R':\n",
    "            compiled_regex_string += '[AG]'\n",
    "        elif base == 'Y':\n",
    "            compiled_regex_string += '[CT]'\n",
    "        elif base == 'K':\n",
    "            compiled_regex_string += '[GT]'\n",
    "        elif base == \"M\":\n",
    "            compiled_regex_string += '[AC]'\n",
    "        elif base == 'S':\n",
    "            compiled_regex_string += '[CG]'\n",
    "        elif base == 'W':\n",
    "            compiled_regex_string += '[AT]'\n",
    "        elif base == 'B':\n",
    "            compiled_regex_string += '[CGT]'\n",
    "        elif base == 'D':\n",
    "            compiled_regex_string += '[AGT]'\n",
    "        elif base == 'H':\n",
    "            compiled_regex_string += '[ACT]'\n",
    "        elif base == 'V':\n",
    "            compiled_regex_string += '[ACG]'\n",
    "        elif base == 'N':\n",
    "            compiled_regex_string += '[ATCG]'\n",
    "                    \n",
    "        \n",
    "    compiled_regex = re.compile(compiled_regex_string)\n",
    "    return(compiled_regex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example\n",
    "\n",
    "lets pretend there's an alien world where the bases are coded differently:\n",
    "\n",
    "Normal bases:\n",
    "- __P__ pairs with __T__\n",
    "- __K__ pairs with __L__\n",
    "\n",
    "Degenerate codes:\n",
    "- __M__ codes for either __P__ or __T__\n",
    "- __N__ codes for either __K__ or __L__\n",
    "- __X__ codes for any base\n",
    "\n",
    "Like above, to help a friend out you've been asked to write a function that takes the degenerate coding, for instance the degenerate sequence __PM__ which could be either __PP__ or __PT__, and creates a regular expression that finds that sequence somewhere in a genome. Here's something you put together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alien_restriction_regex_generator(sequence_pattern):\n",
    "    resulting_alien_regex_string = ''\n",
    "    \n",
    "    for alien_base in sequence_pattern:\n",
    "        if alien_base == 'P' or alien_base == 'T' or alien_base == 'K' or alien_base == 'L':\n",
    "            resulting_alien_regex_string += alien_base\n",
    "        if alien_base == 'M':\n",
    "            resulting_alien_regex_string += '[PT]'\n",
    "        if alien_base == 'N':\n",
    "            resulting_alien_regex_string += '[KL]'\n",
    "        if alien_base == 'X':\n",
    "            resulting_alien_regex_string += '[PTKL]'\n",
    "    \n",
    "    compiled_regex = pattern = re.compile(resulting_alien_regex_string)\n",
    "    \n",
    "    return(compiled_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the alien function\n",
    "\n",
    "Now that you've written your function, you want to test it in a number of different ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile('PT[PT][KL]')\n",
      "found PTTK\n",
      "found PTTL\n",
      "did not find string matching the pattern\n"
     ]
    }
   ],
   "source": [
    "alien_regex_for_PTMN = alien_restriction_regex_generator(\"PTMN\")\n",
    "\n",
    "# show what the resulting pattern looks like\n",
    "print(alien_regex_for_PTMN)\n",
    "\n",
    "# this should result in match\n",
    "match = alien_regex_for_PTMN.search(\"PTTK\")\n",
    "if match:\n",
    "  print('found', match.group())\n",
    "else:\n",
    "  print('did not find string matching the pattern')\n",
    "\n",
    "# this should also result in match\n",
    "match = alien_regex_for_PTMN.search(\"PTTL\")\n",
    "if match:\n",
    "  print('found', match.group())\n",
    "else:\n",
    "  print('did not find string matching the pattern')\n",
    "\n",
    "\n",
    "# this should NOT match\n",
    "match = alien_regex_for_PTMN.search(\"PTKT\")\n",
    "if match:\n",
    "  print('found', match.group())\n",
    "else:\n",
    "  print('did not find string matching the pattern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE 6.0\n"
     ]
    }
   ],
   "source": [
    "def reverse_generator(pattern):\n",
    "    results = [\"\"]\n",
    "    for base in pattern:\n",
    "        if base == 'A' or base == 'T' or base == 'C' or base == 'G':\n",
    "            results = [r + base for r in results]\n",
    "        elif base == 'R':\n",
    "            new_results = []\n",
    "            for i in ['A','G']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "            \n",
    "        elif base == 'Y':\n",
    "            new_results = []\n",
    "            for i in ['C','T']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'K':\n",
    "            new_results = []\n",
    "            for i in ['G','T']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == \"M\":\n",
    "            new_results = []\n",
    "            for i in ['A','C']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'S':\n",
    "            new_results = []\n",
    "            for i in ['G','C']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'W':\n",
    "            new_results = []\n",
    "            for i in ['A','T']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'B':\n",
    "            new_results = []\n",
    "            for i in ['T','G','C']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'D':\n",
    "            new_results = []\n",
    "            for i in ['A','G','T']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'H':\n",
    "            new_results = []\n",
    "            for i in ['A','C','T']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'V':\n",
    "            new_results = []\n",
    "            for i in ['A','G','C']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'N':\n",
    "            new_results = []\n",
    "            for i in ['A','G','T','C']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "    return(results)\n",
    "\n",
    "def other_base(base):\n",
    "    if base == 'A':\n",
    "        return('G')\n",
    "    if base == 'T':\n",
    "        return('C')\n",
    "    if base == 'G':\n",
    "        return('A')\n",
    "    if base == 'C':\n",
    "        return('T')\n",
    "    return 'N'\n",
    "\n",
    "def reverse_NOT_generator(pattern):\n",
    "    results = [\"\"]\n",
    "    for base in pattern:\n",
    "        if base == 'A' or base == 'T' or base == 'C' or base == 'G':\n",
    "            results = [other_base(r) + base for r in results]\n",
    "        elif base == 'Y':\n",
    "            new_results = []\n",
    "            for i in ['A','G']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "            \n",
    "        elif base == 'R':\n",
    "            new_results = []\n",
    "            for i in ['C','T']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'M':\n",
    "            new_results = []\n",
    "            for i in ['G','T']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == \"K\":\n",
    "            new_results = []\n",
    "            for i in ['A','C']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'W':\n",
    "            new_results = []\n",
    "            for i in ['G','C']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'S':\n",
    "            new_results = []\n",
    "            for i in ['A','T']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'B':\n",
    "            new_results = []\n",
    "            for i in ['A']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'D':\n",
    "            new_results = []\n",
    "            for i in ['C']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'H':\n",
    "            new_results = []\n",
    "            for i in ['G']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'V':\n",
    "            new_results = []\n",
    "            for i in ['T']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "        elif base == 'N':\n",
    "            new_results = []\n",
    "            for i in ['N']:\n",
    "                new_results.extend([r + i for r in results])\n",
    "            results = new_results\n",
    "    return(results)\n",
    "\n",
    "\n",
    "total = 0\n",
    "pos = 0\n",
    "failures = 0\n",
    "failure_test = 0\n",
    "with open(\"restriction_enzymes_promega.txt\") as promega_file:\n",
    "    header = promega_file.readline()\n",
    "    for restriction_line in promega_file:\n",
    "        # print(restriction_line)\n",
    "        line_split_into_tokens = restriction_line.strip().split(\"\\t\")\n",
    "        patterns = reverse_generator(line_split_into_tokens[1])\n",
    "        \n",
    "        at = restriction_regex_generator(line_split_into_tokens[1])\n",
    "        # print(patterns)\n",
    "        for pattern in patterns:\n",
    "            total += 1\n",
    "            match=at.search(pattern)\n",
    "            if match:\n",
    "                pos += 1\n",
    "        \n",
    "        patterns = reverse_NOT_generator(line_split_into_tokens[1])\n",
    "        # print(patterns)\n",
    "        for pattern in patterns:\n",
    "            failure_test += 1\n",
    "            match=at.search(pattern)\n",
    "            if match:\n",
    "                failures += 1\n",
    "            \n",
    "print(\"SCORE \" + str(6 * (pos/total)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
